{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "frTMl3sShA3P"
   },
   "outputs": [],
   "source": [
    "from __future__ import absolute_import\n",
    "from __future__ import division\n",
    "from __future__ import print_function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     },
     "height": 321,
     "output_extras": [
      {
       "item_id": 1
      }
     ]
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 2880,
     "status": "error",
     "timestamp": 1505781339378,
     "user": {
      "displayName": "Sara Robinson",
      "photoUrl": "//lh4.googleusercontent.com/-RR9n0dvbwgI/AAAAAAAAAAI/AAAAAAAAMYM/SOr5ZExpvXE/s50-c-k-no/photo.jpg",
      "userId": "112510032804989247452"
     },
     "user_tz": 240
    },
    "id": "783h64rGhA3T",
    "outputId": "d447b2ab-e321-4ee5-abd4-de2c0116302f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You have TensorFlow version 1.7.0\n"
     ]
    }
   ],
   "source": [
    "import itertools\n",
    "import os\n",
    "import math\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from tensorflow.python import keras\n",
    "layers = keras.layers\n",
    "\n",
    "# This code was tested with TensorFlow v1.7\n",
    "print(\"You have TensorFlow version\", tf.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "c7te21f7hA3V"
   },
   "outputs": [],
   "source": [
    "# TODO: download the data here and copy it into your local directory: https://www.kaggle.com/zynicide/wine-reviews/data\n",
    "data = pd.read_csv(\"winemag-data_first150k.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     },
     "output_extras": [
      {}
     ]
    },
    "colab_type": "code",
    "id": "chAbp3ryhA3X",
    "outputId": "3a16921d-a3be-4c43-a5e2-6012220ee13a"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>country</th>\n",
       "      <th>description</th>\n",
       "      <th>designation</th>\n",
       "      <th>points</th>\n",
       "      <th>price</th>\n",
       "      <th>province</th>\n",
       "      <th>region_1</th>\n",
       "      <th>region_2</th>\n",
       "      <th>variety</th>\n",
       "      <th>winery</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>49599</th>\n",
       "      <td>49599</td>\n",
       "      <td>Germany</td>\n",
       "      <td>This is a relatively tame Scheurebe, but one t...</td>\n",
       "      <td>Trocken</td>\n",
       "      <td>87</td>\n",
       "      <td>25.0</td>\n",
       "      <td>Pfalz</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Scheurebe</td>\n",
       "      <td>Weegmüller</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47016</th>\n",
       "      <td>47016</td>\n",
       "      <td>Argentina</td>\n",
       "      <td>Tough cherry and plum aromas lead it off, foll...</td>\n",
       "      <td>Los Cardos</td>\n",
       "      <td>84</td>\n",
       "      <td>10.0</td>\n",
       "      <td>Mendoza Province</td>\n",
       "      <td>Mendoza</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Syrah</td>\n",
       "      <td>Doña Paula</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>140691</th>\n",
       "      <td>140691</td>\n",
       "      <td>US</td>\n",
       "      <td>Give this Mendocino-grown Riesling a bit more ...</td>\n",
       "      <td>McFadden Farms Dry</td>\n",
       "      <td>86</td>\n",
       "      <td>20.0</td>\n",
       "      <td>California</td>\n",
       "      <td>Potter Valley</td>\n",
       "      <td>Mendocino/Lake Counties</td>\n",
       "      <td>Riesling</td>\n",
       "      <td>Dashe Cellars</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25123</th>\n",
       "      <td>25123</td>\n",
       "      <td>Italy</td>\n",
       "      <td>Created to celebrate a 50th wedding anniversar...</td>\n",
       "      <td>Nozze d'Oro</td>\n",
       "      <td>88</td>\n",
       "      <td>30.0</td>\n",
       "      <td>Sicily &amp; Sardinia</td>\n",
       "      <td>Contea di Sclafani</td>\n",
       "      <td>NaN</td>\n",
       "      <td>White Blend</td>\n",
       "      <td>Tasca d'Almerita</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>94707</th>\n",
       "      <td>94707</td>\n",
       "      <td>US</td>\n",
       "      <td>The blend is classic Bordeaux—85% Cabernet Sau...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>92</td>\n",
       "      <td>50.0</td>\n",
       "      <td>Washington</td>\n",
       "      <td>Columbia Valley (WA)</td>\n",
       "      <td>Columbia Valley</td>\n",
       "      <td>Cabernet Sauvignon</td>\n",
       "      <td>Pepper Bridge</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        Unnamed: 0    country  \\\n",
       "49599        49599    Germany   \n",
       "47016        47016  Argentina   \n",
       "140691      140691         US   \n",
       "25123        25123      Italy   \n",
       "94707        94707         US   \n",
       "\n",
       "                                              description         designation  \\\n",
       "49599   This is a relatively tame Scheurebe, but one t...             Trocken   \n",
       "47016   Tough cherry and plum aromas lead it off, foll...          Los Cardos   \n",
       "140691  Give this Mendocino-grown Riesling a bit more ...  McFadden Farms Dry   \n",
       "25123   Created to celebrate a 50th wedding anniversar...         Nozze d'Oro   \n",
       "94707   The blend is classic Bordeaux—85% Cabernet Sau...                 NaN   \n",
       "\n",
       "        points  price           province              region_1  \\\n",
       "49599       87   25.0              Pfalz                   NaN   \n",
       "47016       84   10.0   Mendoza Province               Mendoza   \n",
       "140691      86   20.0         California         Potter Valley   \n",
       "25123       88   30.0  Sicily & Sardinia    Contea di Sclafani   \n",
       "94707       92   50.0         Washington  Columbia Valley (WA)   \n",
       "\n",
       "                       region_2             variety            winery  \n",
       "49599                       NaN           Scheurebe        Weegmüller  \n",
       "47016                       NaN               Syrah        Doña Paula  \n",
       "140691  Mendocino/Lake Counties            Riesling     Dashe Cellars  \n",
       "25123                       NaN         White Blend  Tasca d'Almerita  \n",
       "94707           Columbia Valley  Cabernet Sauvignon     Pepper Bridge  "
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Shuffle the data\n",
    "data = data.sample(frac=1)\n",
    "\n",
    "# Print the first 5 rows\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Do some preprocessing to limit the # of wine varities in the dataset\n",
    "data = data[pd.notnull(data['country'])]\n",
    "data = data[pd.notnull(data['price'])]\n",
    "data = data.drop(data.columns[0], axis=1) \n",
    "\n",
    "variety_threshold = 500 # Anything that occurs less than this will be removed.\n",
    "value_counts = data['variety'].value_counts()\n",
    "to_remove = value_counts[value_counts <= variety_threshold].index\n",
    "data.replace(to_remove, np.nan, inplace=True)\n",
    "data = data[pd.notnull(data['variety'])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     },
     "output_extras": [
      {}
     ]
    },
    "colab_type": "code",
    "id": "h_SDal0khA3n",
    "outputId": "e6c311e5-c674-4cf2-f2dc-d6ceabfa6f83",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train size: 95646\n",
      "Test size: 23912\n"
     ]
    }
   ],
   "source": [
    "# Split data into train and test\n",
    "train_size = int(len(data) * .8)\n",
    "print (\"Train size: %d\" % train_size)\n",
    "print (\"Test size: %d\" % (len(data) - train_size))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "anD38iilhA3r"
   },
   "outputs": [],
   "source": [
    "# Train features\n",
    "description_train = data['description'][:train_size]\n",
    "variety_train = data['variety'][:train_size]\n",
    "\n",
    "# Train labels\n",
    "labels_train = data['price'][:train_size]\n",
    "\n",
    "# Test features\n",
    "description_test = data['description'][train_size:]\n",
    "variety_test = data['variety'][train_size:]\n",
    "\n",
    "# Test labels\n",
    "labels_test = data['price'][train_size:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "z4GblctFhA3u"
   },
   "outputs": [],
   "source": [
    "# Create a tokenizer to preprocess our text descriptions\n",
    "vocab_size = 100000\n",
    "tokenize = keras.preprocessing.text.Tokenizer(num_words=vocab_size, char_level=False)\n",
    "tokenize.fit_on_texts(description_train) # only fit on train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "YatMLCKXhA3x"
   },
   "outputs": [],
   "source": [
    "# Wide feature 1: sparse bag of words (bow) vocab_size vector \n",
    "description_bow_train = tokenize.texts_to_matrix(description_train)\n",
    "description_bow_test = tokenize.texts_to_matrix(description_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "8quTsErLhA3z"
   },
   "outputs": [],
   "source": [
    "# Wide feature 2: one-hot vector of variety categories\n",
    "\n",
    "# Use sklearn utility to convert label strings to numbered index\n",
    "encoder = LabelEncoder()\n",
    "encoder.fit(variety_train)\n",
    "variety_train = encoder.transform(variety_train)\n",
    "variety_test = encoder.transform(variety_test)\n",
    "num_classes = np.max(variety_train) + 1\n",
    "\n",
    "# Convert labels to one hot\n",
    "variety_train = keras.utils.to_categorical(variety_train, num_classes)\n",
    "variety_test = keras.utils.to_categorical(variety_test, num_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define our wide model with the functional API\n",
    "bow_inputs = layers.Input(shape=(vocab_size,))\n",
    "variety_inputs = layers.Input(shape=(num_classes,))\n",
    "merged_layer = layers.concatenate([bow_inputs, variety_inputs])\n",
    "merged_layer = layers.Dense(256, activation='relu')(merged_layer)\n",
    "predictions = layers.Dense(1)(merged_layer)\n",
    "wide_model = keras.Model(inputs=[bow_inputs, variety_inputs], outputs=predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            (None, 100000)       0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_2 (InputLayer)            (None, 40)           0                                            \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_1 (Concatenate)     (None, 100040)       0           input_1[0][0]                    \n",
      "                                                                 input_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_1 (Dense)                 (None, 256)          25610496    concatenate_1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dense_2 (Dense)                 (None, 1)            257         dense_1[0][0]                    \n",
      "==================================================================================================\n",
      "Total params: 25,610,753\n",
      "Trainable params: 25,610,753\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "wide_model.compile(loss='mse', optimizer='adam', metrics=['accuracy'])\n",
    "print(wide_model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Deep model feature: word embeddings of wine descriptions\n",
    "train_embed = tokenize.texts_to_sequences(description_train)\n",
    "test_embed = tokenize.texts_to_sequences(description_test)\n",
    "\n",
    "max_seq_length = 170\n",
    "train_embed = keras.preprocessing.sequence.pad_sequences(\n",
    "    train_embed, maxlen=max_seq_length, padding=\"post\")\n",
    "test_embed = keras.preprocessing.sequence.pad_sequences(\n",
    "    test_embed, maxlen=max_seq_length, padding=\"post\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_3 (InputLayer)         (None, 170)               0         \n",
      "_________________________________________________________________\n",
      "embedding_1 (Embedding)      (None, 170, 8)            800000    \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 1360)              0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 1)                 1361      \n",
      "=================================================================\n",
      "Total params: 801,361\n",
      "Trainable params: 801,361\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "# Define our deep model with the Functional API\n",
    "deep_inputs = layers.Input(shape=(max_seq_length,))\n",
    "embedding = layers.Embedding(vocab_size, 8, input_length=max_seq_length)(deep_inputs)\n",
    "embedding = layers.Flatten()(embedding)\n",
    "embed_out = layers.Dense(1)(embedding)\n",
    "deep_model = keras.Model(inputs=deep_inputs, outputs=embed_out)\n",
    "print(deep_model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "deep_model.compile(loss='mse',\n",
    "                       optimizer='adam',\n",
    "                       metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            (None, 100000)       0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_2 (InputLayer)            (None, 40)           0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_3 (InputLayer)            (None, 170)          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_1 (Concatenate)     (None, 100040)       0           input_1[0][0]                    \n",
      "                                                                 input_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "embedding_1 (Embedding)         (None, 170, 8)       800000      input_3[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_1 (Dense)                 (None, 256)          25610496    concatenate_1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "flatten_1 (Flatten)             (None, 1360)         0           embedding_1[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "dense_2 (Dense)                 (None, 1)            257         dense_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_3 (Dense)                 (None, 1)            1361        flatten_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_2 (Concatenate)     (None, 2)            0           dense_2[0][0]                    \n",
      "                                                                 dense_3[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_4 (Dense)                 (None, 1)            3           concatenate_2[0][0]              \n",
      "==================================================================================================\n",
      "Total params: 26,412,117\n",
      "Trainable params: 26,412,117\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "# Combine wide and deep into one model\n",
    "merged_out = layers.concatenate([wide_model.output, deep_model.output])\n",
    "merged_out = layers.Dense(1)(merged_out)\n",
    "combined_model = keras.Model(wide_model.input + [deep_model.input], merged_out)\n",
    "print(combined_model.summary())\n",
    "\n",
    "combined_model.compile(loss='mse',\n",
    "                       optimizer='adam',\n",
    "                       metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "gtP-hDRZhA31"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "95646/95646 [==============================] - 380s 4ms/step - loss: 1069.3076 - acc: 0.0314\n",
      "Epoch 2/10\n",
      "95646/95646 [==============================] - 400s 4ms/step - loss: 925.3823 - acc: 0.0380\n",
      "Epoch 3/10\n",
      "95646/95646 [==============================] - 394s 4ms/step - loss: 813.1365 - acc: 0.0409\n",
      "Epoch 4/10\n",
      "95646/95646 [==============================] - 400s 4ms/step - loss: 711.3324 - acc: 0.0428\n",
      "Epoch 5/10\n",
      "95646/95646 [==============================] - 401s 4ms/step - loss: 617.2445 - acc: 0.0471\n",
      "Epoch 6/10\n",
      "95646/95646 [==============================] - 394s 4ms/step - loss: 534.9507 - acc: 0.0511\n",
      "Epoch 7/10\n",
      "95646/95646 [==============================] - 391s 4ms/step - loss: 464.3987 - acc: 0.0556\n",
      "Epoch 8/10\n",
      "95646/95646 [==============================] - 385s 4ms/step - loss: 404.9867 - acc: 0.0604\n",
      "Epoch 9/10\n",
      "95646/95646 [==============================] - 387s 4ms/step - loss: 356.1492 - acc: 0.0650\n",
      "Epoch 10/10\n",
      "95646/95646 [==============================] - 391s 4ms/step - loss: 315.8375 - acc: 0.0694\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras._impl.keras.callbacks.History at 0x13e197c18>"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Run training (need to run this for at least 5 epochs to get good accuracy, should probably do this on the cloud)\n",
    "combined_model.fit([description_bow_train, variety_train] + [train_embed], labels_train, epochs=10, batch_size=256)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23912/23912 [==============================] - 50s 2ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[710.8771138196009, 0.059677149558314595]"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "combined_model.evaluate([description_bow_test, variety_test] + [test_embed], labels_test, batch_size=256)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_model.save('wine_model_2_features_10_epochs.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     },
     "output_extras": [
      {}
     ]
    },
    "colab_type": "code",
    "id": "f000lYoxhA4F",
    "outputId": "21cd198f-1979-4b40-a2fd-891a1c0248db"
   },
   "outputs": [],
   "source": [
    "# Generate predictions\n",
    "predictions = combined_model.predict([description_bow_test, variety_test] + [test_embed])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fragrant apple blossoms and honey perfume this deliciously fresh and fruity Sauvignon Blanc. The dry palate is full bodied with a shower of white peach flavors marked by a quirky lemongrass note and a bright lemon-lime acidity.\n",
      "19.881979 Actual:  15.0 \n",
      "\n",
      "The wine is built around flavors of crisp citrus, white peach and green apple fruits, wrapped in a pleasing minerality. It's all quite fresh and nicely textured. Just a bit of citrus rind enlivens the lengthy finish.\n",
      "24.543623 Actual:  25.0 \n",
      "\n",
      "A rich nose of clove, tea, mint and cedar start this red from Greece. The palate offers clean bursts of cedar, spice and red currant. Fresh and light, the wine is a good house red.\n",
      "19.474958 Actual:  21.0 \n",
      "\n",
      "Ultraripe tropical fruits—even including hints of bananas—dominate this wine's heady aromas. Acids are soft, and alcohol fairly elevated—12.5%—for a wine of this prädikat. There's ample concentration, and the peach and melon flavors linger on the finish. Drink now–2016.\n",
      "53.24802 Actual:  50.0 \n",
      "\n",
      "The bubbles here aren't very plentiful or vigorous, but this wine offers pleasant peach, orange and toast flavors, a soft mousse and a clean, fresh finish. A decent value in bubbly, just don't expect a lot of bubble.\n",
      "10.250185 Actual:  11.0 \n",
      "\n",
      "A little sweet with the glycerine of high alcohol, and there may be some residual sugar. That gives the raspberry, cherry and blackberry fruit a jelly-jam richness, with nuances of chocolate, anise liqueur and toast. Drink now.\n",
      "30.37032 Actual:  27.0 \n",
      "\n",
      "Smooth and consistent Malbec from Cafayate is what Michel Torino is all about. Don David is a higher-aiming effort, and while it shows a touch of northern Argentina's herbal, sun-affected characteristics, it's also a well-balanced, formulaic Malbec that hits all the markers: good color, nice body, friendly tannins and plenty of oak.\n",
      "12.132054 Actual:  15.0 \n",
      "\n",
      "Extraordinarily rich, a tremendous Syrah from this unique vineyard in the heart of the valley. Black in color and bone dry, it explodes in concentrated blackberry, blueberry, cassis, mocha, pepper and sandalwood flavors, but even more impressive is the tannic structure: so soft, intricate and silky. Wonderful with spicy pork and beef dishes.\n",
      "50.303345 Actual:  55.0 \n",
      "\n",
      "This Pinot Grigio is ripe and round without being overly heavy, marrying muskmelon and nectarine flavors to a cool, refreshing finish. Drink now.\n",
      "18.792898 Actual:  12.0 \n",
      "\n",
      "Round and beautifully fragrant, with smoky nuances atop defined, elegant black fruit. What a stud this wine is; the palate is perfectly ripe, with a touch of oaky vanilla supporting first-class red and black fruits. The finish is clean, smooth and pleasant. It's a stellar Super Tuscan, a leader in its field for sure. And it gets better every minute the bottle is open.\n",
      "64.31677 Actual:  51.0 \n",
      "\n",
      "This is Oregon Pinot from the Columbia Gorge AVA. This new region is still defining itself, but on first blush it's warmer, with more ripe, sweet strawberry fruit and very little of the herbal, resiny, tomato leaf character of most Oregon Pinots in this price range. This is sweet, jammy, spicy and thick, with fruit compote flavors dominating.\n",
      "22.10356 Actual:  24.0 \n",
      "\n",
      "With classic raspberry, cherry and sandalwood flavors, wrapped into a delicately crisp mouthfeel, this is a classic Russian River Pinot for drinking now. Everything about it suggests beef, whether it's in a taco or a full-fledged steak.\n",
      "35.776157 Actual:  28.0 \n",
      "\n",
      "Fresh, spicy and floral, this Rhône-style blend of Viognier, Crouchen Blanc, Chenin Blanc, Pinot Gris and Muscat offers a zing on the palate with complex waves of melon and tropical fruit. Fresh and expressive.\n",
      "12.596775 Actual:  10.0 \n",
      "\n",
      "Quite dry, all stainless fermentation, with plenty of herbal components as the wine rounds into maturity. It develops some pretty cotton candy scents as it warms in the glass also.\n",
      "15.9961 Actual:  15.0 \n",
      "\n",
      "Plump red cherry and star anise aromas meet sagebrush and rust on the nose of this appellation blend. It's light bodied on the palate, where tangy acidity presents cranberry, mace and dried meat flavors.\n",
      "38.77131 Actual:  30.0 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Compare predictions with actual values for the first few items in our test dataset\n",
    "for i in range(15):\n",
    "    val = predictions[i]\n",
    "    print(description_test.iloc[i])\n",
    "    print(val[0], 'Actual: ', labels_test.iloc[i], '\\n')"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "default_view": {},
   "name": "josh3.ipynb",
   "provenance": [],
   "version": "0.3.2",
   "views": {}
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
